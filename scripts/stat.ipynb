{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIDE exp results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "root_path = '/home/v-yuanteli/aide_gpt_4o_our_results/2025-03-04T01-11-04-GMT_run-group_aide'\n",
    "all_dfs = []\n",
    "\n",
    "for competition in os.listdir(root_path):\n",
    "    competition_path = os.path.join(root_path, competition)\n",
    "\n",
    "    if not os.path.isdir(competition_path):\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(competition_path, 'logs/journal.json')\n",
    "    log_path = os.path.join(competition_path, 'logs/aide.log')\n",
    "    base_path = competition_path\n",
    "    \n",
    "    if not os.path.exists(file_path) or not os.path.exists(log_path):\n",
    "        continue\n",
    "    \n",
    "    # extract JSON for each loop's info\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read().strip()\n",
    "        if not content:\n",
    "            print(f\"Error: {file_path} is empty, skipping this competition.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            data = json.loads(content)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error: read {file_path} failed, error info is : {e}\")\n",
    "            continue\n",
    "\n",
    "    \n",
    "    nodes = data.get('nodes', [])\n",
    "    records = []\n",
    "    for node in nodes:\n",
    "        step = node.get('step')\n",
    "        node_id = node.get('id')\n",
    "        metric = node.get('metric', {})\n",
    "        is_buggy = node.get('is_buggy')\n",
    "        records.append({'step': step, 'id': node_id, 'metric': metric, 'is_buggy': is_buggy})\n",
    "    \n",
    "    df = pd.DataFrame(records)\n",
    "    \n",
    "    # extract time\n",
    "    with open(log_path, 'r') as file:\n",
    "        log = file.read()\n",
    "    \n",
    "    pattern = r'\\[(.*?)\\] INFO: Agent is generating code, parent node type'\n",
    "    times = re.findall(pattern, log)\n",
    "    \n",
    "    if len(times) > len(df):\n",
    "        new_row = pd.DataFrame([{'step': df['step'].iloc[-1] + 1, 'id': '', 'metric': {}, 'is_buggy': None}])\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "    \n",
    "    df['times'] = times[:len(df)]\n",
    "    \n",
    "    maximize = None\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if row['metric'].get('maximize') is not None:\n",
    "            maximize = row['metric']['maximize']\n",
    "            break\n",
    "    \n",
    "    if maximize is None:\n",
    "        df['sota'] = None\n",
    "    else:\n",
    "        if maximize:\n",
    "            max_value = -np.inf\n",
    "            def calculate_sota(row, max_value=[-np.inf]):\n",
    "                metric = row['metric']\n",
    "                if metric.get('value') is None:\n",
    "                    return None\n",
    "                if metric['value'] > max_value[0]:\n",
    "                    max_value[0] = metric['value']\n",
    "                    return True\n",
    "                return False\n",
    "        else:\n",
    "            min_value = np.inf\n",
    "            def calculate_sota(row, min_value=[np.inf]):\n",
    "                metric = row['metric']\n",
    "                if metric.get('value') is None:\n",
    "                    return None\n",
    "                if metric['value'] < min_value[0]:\n",
    "                    min_value[0] = metric['value']\n",
    "                    return True\n",
    "                return False\n",
    "    \n",
    "        df['sota'] = df.apply(calculate_sota, axis=1)\n",
    "    \n",
    "    # extract grading data\n",
    "    grading_folders = [f for f in os.listdir(base_path) if f.startswith('grading_output_') and os.path.isdir(os.path.join(base_path, f))]\n",
    "    scores = []\n",
    "    \n",
    "    for folder in grading_folders:\n",
    "        folder_path = os.path.join(base_path, folder)\n",
    "        folder_number = int(folder.split('_')[-1])\n",
    "        json_files = [f for f in os.listdir(folder_path) if f.endswith('.json')]\n",
    "        assert len(json_files) == 1, f\"Expected exactly one JSON file in {folder_path}, but found {len(json_files)}\"\n",
    "        \n",
    "        json_path = os.path.join(folder_path, json_files[0])\n",
    "        with open(json_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            competition_reports = data.get('competition_reports', [])\n",
    "            score = competition_reports[0].get('score') if competition_reports else None\n",
    "            rank = competition_reports[0].get('rank') if competition_reports else None\n",
    "            any_medal = competition_reports[0].get('any_medal') if competition_reports else None\n",
    "            gold_medal = competition_reports[0].get('gold_medal') if competition_reports else None\n",
    "            silver_medal = competition_reports[0].get('silver_medal') if competition_reports else None\n",
    "            bronze_medal = competition_reports[0].get('bronze_medal') if competition_reports else None\n",
    "            above_median = competition_reports[0].get('above_median') if competition_reports else None\n",
    "            submission_exists = competition_reports[0].get('submission_exists') if competition_reports else None\n",
    "            valid_submission = competition_reports[0].get('valid_submission') if competition_reports else None\n",
    "            scores.append({'folder_number': folder_number, 'score_loop': score, 'rank': rank, 'any_medal': any_medal, 'gold_medal': gold_medal, 'silver_medal': silver_medal, 'bronze_medal': bronze_medal, 'above_median': above_median, 'submission_exists': submission_exists, 'valid_submission': valid_submission})\n",
    "    \n",
    "    scores_df = pd.DataFrame(scores)\n",
    "\n",
    "    if not scores_df.empty:\n",
    "        scores_df = scores_df.sort_values(by='folder_number').reset_index(drop=True)\n",
    "        for col in ['score_loop', 'rank', 'any_medal', 'gold_medal', 'silver_medal', 'bronze_medal', 'above_median', 'submission_exists', 'valid_submission']:\n",
    "            score_dict = scores_df.set_index('folder_number')[col].to_dict()\n",
    "            df[col] = df['step'].map(score_dict)\n",
    "    else:\n",
    "        for col in ['score_loop', 'rank', 'any_medal', 'gold_medal', 'silver_medal', 'bronze_medal', 'above_median', 'submission_exists', 'valid_submission']:\n",
    "            df[col] = None\n",
    "    \n",
    "    df['score'] = df['score_loop'].copy()\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        if df.at[i, 'sota'] != True:\n",
    "            for col in ['score', 'rank', 'any_medal', 'gold_medal', 'silver_medal', 'bronze_medal', 'above_median', 'submission_exists', 'valid_submission']:\n",
    "                df.at[i, col] = df.at[i-1, col]\n",
    "    \n",
    "    df['competition'] = competition\n",
    "    all_dfs.append(df)\n",
    "\n",
    "final_df = pd.concat(all_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('aide_gpt_4o_our_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate 11 hours AIDE exp results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metrics = [\"any_medal\", \"gold_medal\", \"silver_medal\", \"bronze_medal\", \"above_median\", \"submission_exists\", \"valid_submission\"]\n",
    "df = pd.read_csv('aide_gpt_4o_our_results.csv')\n",
    "df['relative_time'] = pd.to_datetime(df['times']) - pd.to_datetime(df['times'].min())\n",
    "\n",
    "def compute_ratio_within_time(df, metric, hours):\n",
    "    df_time = df[df['relative_time'] <= pd.Timedelta(hours=hours)]\n",
    "    if df_time.empty:\n",
    "        return 0\n",
    "\n",
    "    last_entries = df_time.groupby('competition').apply(lambda x: x.loc[x['relative_time'].idxmax()])\n",
    "    return last_entries[metric].sum() / 22 if last_entries.shape[0] > 0 else 0\n",
    "\n",
    "aide_ratios_11h = {metric: round(compute_ratio_within_time(df, metric, 11) * 100, 1) for metric in metrics}\n",
    "aide_ratios_11h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "root_path = '/home/v-yuanteli/aide_gpt_4o_our_results/2025-03-04T01-11-04-GMT_run-group_aide'\n",
    "all_dfs = []\n",
    "\n",
    "for competition in os.listdir(root_path):\n",
    "    competition_path = os.path.join(root_path, competition)\n",
    "    if not competition.startswith('aerial-cactus-identification'):\n",
    "        continue\n",
    "    if not os.path.isdir(competition_path):\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(competition_path, 'logs/journal.json')\n",
    "    log_path = os.path.join(competition_path, 'logs/aide.log')\n",
    "    base_path = competition_path\n",
    "    \n",
    "    if not os.path.exists(file_path) or not os.path.exists(log_path):\n",
    "        continue\n",
    "    \n",
    "    # extract JSON for each loop's info\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read().strip()\n",
    "        if not content:\n",
    "            print(f\"Error: {file_path} is empty, skipping this competition.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            data = json.loads(content)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error: read {file_path} failed, error info is : {e}\")\n",
    "            continue\n",
    "\n",
    "    \n",
    "    nodes = data.get('nodes', [])\n",
    "    records = []\n",
    "    for node in nodes:\n",
    "        step = node.get('step')\n",
    "        node_id = node.get('id')\n",
    "        metric = node.get('metric', {})\n",
    "        is_buggy = node.get('is_buggy')\n",
    "        records.append({'step': step, 'id': node_id, 'metric': metric, 'is_buggy': is_buggy})\n",
    "    \n",
    "    df = pd.DataFrame(records)\n",
    "    \n",
    "    # extract time\n",
    "    with open(log_path, 'r') as file:\n",
    "        log = file.read()\n",
    "    \n",
    "    pattern = r'\\[(.*?)\\] INFO: Agent is generating code, parent node type'\n",
    "    times = re.findall(pattern, log)\n",
    "    \n",
    "    if len(times) > len(df):\n",
    "        new_row = pd.DataFrame([{'step': df['step'].iloc[-1] + 1, 'id': '', 'metric': {}, 'is_buggy': None}])\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "    \n",
    "    df['times'] = times[:len(df)]\n",
    "    \n",
    "    maximize = None\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if row['metric'].get('maximize') is not None:\n",
    "            maximize = row['metric']['maximize']\n",
    "            break\n",
    "    \n",
    "    if maximize is None:\n",
    "        df['sota'] = None\n",
    "    else:\n",
    "        if maximize:\n",
    "            max_value = -np.inf\n",
    "            def calculate_sota(row, max_value=[-np.inf]):\n",
    "                metric = row['metric']\n",
    "                if metric.get('value') is None:\n",
    "                    return None\n",
    "                if metric['value'] > max_value[0]:\n",
    "                    max_value[0] = metric['value']\n",
    "                    return True\n",
    "                return False\n",
    "        else:\n",
    "            min_value = np.inf\n",
    "            def calculate_sota(row, min_value=[np.inf]):\n",
    "                metric = row['metric']\n",
    "                if metric.get('value') is None:\n",
    "                    return None\n",
    "                if metric['value'] < min_value[0]:\n",
    "                    min_value[0] = metric['value']\n",
    "                    return True\n",
    "                return False\n",
    "    \n",
    "        df['sota'] = df.apply(calculate_sota, axis=1)\n",
    "    \n",
    "    # extract grading data\n",
    "    grading_folders = [f for f in os.listdir(base_path) if f.startswith('grading_output_') and os.path.isdir(os.path.join(base_path, f))]\n",
    "    scores = []\n",
    "    \n",
    "    for folder in grading_folders:\n",
    "        folder_path = os.path.join(base_path, folder)\n",
    "        folder_number = int(folder.split('_')[-1])\n",
    "        json_files = [f for f in os.listdir(folder_path) if f.endswith('.json')]\n",
    "        assert len(json_files) == 1, f\"Expected exactly one JSON file in {folder_path}, but found {len(json_files)}\"\n",
    "        \n",
    "        json_path = os.path.join(folder_path, json_files[0])\n",
    "        with open(json_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            competition_reports = data.get('competition_reports', [])\n",
    "            score = competition_reports[0].get('score') if competition_reports else None\n",
    "            scores.append({'folder_number': folder_number, 'score_loop': score})\n",
    "    \n",
    "    scores_df = pd.DataFrame(scores)\n",
    "    if not scores_df.empty:\n",
    "        scores_df = scores_df.sort_values(by='folder_number').reset_index(drop=True)\n",
    "        score_dict = scores_df.set_index('folder_number')['score_loop'].to_dict()\n",
    "        df['score_loop'] = df['step'].map(score_dict)\n",
    "    else:\n",
    "        df['score_loop'] = None\n",
    "    \n",
    "    df['score'] = df['score_loop'].copy()\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        if df.at[i, 'sota'] != True:\n",
    "            df.at[i, 'score'] = df.at[i-1, 'score']\n",
    "    \n",
    "    df['competition'] = competition\n",
    "    all_dfs.append(df)\n",
    "\n",
    "final_df = pd.concat(all_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
